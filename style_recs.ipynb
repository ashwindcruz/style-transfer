{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "\n",
    "This notebook runs through Section 2.2: Style Reconstructions. \n",
    "The images generated are similar to those in Figure 1. \n",
    "\n",
    "The Directory Paths block should be edited to suit local directory structure. \n",
    "The Chosen Parameters block can be changed to try out different experimental settings. \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "\n",
    "from utils.imaging import display_image, format_image, save_image\n",
    "import vgg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directory paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Path to image we are extracting content from\n",
    "real_image_path = './images/starry_night.jpg'\n",
    "\n",
    "# Path to vgg19 checkpoint, must be downloaded separately\n",
    "checkpoint_path = './vgg_19.ckpt'\n",
    "\n",
    "# Location of tensorboard summaries\n",
    "tensorboard_dir = './train/'\n",
    "\n",
    "# Path to directory used for storing images\n",
    "debug_dir = './debug/'\n",
    "\n",
    "# Determines whether information is saved between runs\n",
    "# for tensorboard\n",
    "reset_saves = True\n",
    "if reset_saves is True:\n",
    "    # Ensure tensorboard is not running when you try to delete\n",
    "    # this directory\n",
    "    if os.path.exists(tensorboard_dir):\n",
    "        shutil.rmtree(tensorboard_dir)\n",
    "        \n",
    "# Create the debug directory if it doesn't exist\n",
    "# Tensorboard directory is made automatically if it doesn't exist\n",
    "if os.path.exists(debug_dir):\n",
    "    shutil.rmtree(debug_dir)\n",
    "os.makedirs(debug_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chosen parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dimensions desired for image, channels must be kept as 3\n",
    "height = 224\n",
    "width = 224\n",
    "channels = 3\n",
    "\n",
    "# Set the seeds to provide consistency between runs\n",
    "# Can also comment out for variability between runs\n",
    "np.random.seed(2)\n",
    "tf.set_random_seed(2)\n",
    "\n",
    "# Layer being used to produce features\n",
    "feature_layer_list = ['vgg_19/conv1/conv1_1', 'vgg_19/conv2/conv2_1', 'vgg_19/conv3/conv3_1',\n",
    "    'vgg_19/conv4/conv4_1', 'vgg_19/conv5/conv5_1']\n",
    "\n",
    "# Chosen depth corresponds to how many feature layers you want to use\n",
    "chosen_depth = 2\n",
    "\n",
    "# Learning rate for optimizer\n",
    "learning_rate = 1e-1\n",
    "\n",
    "# Number of training and validation step\n",
    "# In this instance, validation refers to when we would like to examine the \n",
    "# currently optimized image, save it, and loss\n",
    "training_steps = 100000\n",
    "validation_steps = 1000\n",
    "\n",
    "# Online debugging refers to images that will be displayed within the notebook \n",
    "# using plt\n",
    "# Offline debugging refers to images that will be saved to folder using plt\n",
    "debug_online = True\n",
    "debug_offline = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to compute the Gram matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gram_matrix(feature_set):\n",
    "    \"\"\"\n",
    "    Given a set of vectors, in the form of a tensor, from a layer, \n",
    "    compute the Gram matrix (https://en.wikipedia.org/wiki/Gramian_matrix).\n",
    "    \n",
    "    Args:\n",
    "        feature_set: Tensor of vectors \n",
    "            ([1, filter_height, filter_width, num_feature_maps])\n",
    "    Returns:\n",
    "        gram_matrix: Computed Gram matrix ([num_feature_maps, num_feature_maps])\n",
    "    \"\"\"\n",
    "    \n",
    "    batch_size, filter_height, filter_width, num_feature_maps = \\\n",
    "        feature_set.get_shape().as_list()\n",
    "    feature_set = tf.reshape(\n",
    "        feature_set, [filter_height * filter_width, num_feature_maps], name='vectorize_map')\n",
    "    gram_matrix = tf.matmul(\n",
    "        feature_set, feature_set, transpose_a=True, name='gram_map')\n",
    "    \n",
    "    return gram_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to compute the style loss of a single layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def style_layer_loss(gram_matrix_desired, gram_matrix_predicted, filter_size):\n",
    "    \"\"\"\n",
    "    Compute the loss between the gram matrix of the styling image and the\n",
    "    gram matrix of the image undergoing optimization. \n",
    "    \n",
    "    Args:\n",
    "        gram_matrix_desired  : Gram matrix of the styling image\n",
    "        gram_matrix_predicted: Gram matrix of the image undergoing optimization. \n",
    "        filter_size          : The size of an individual filter map (filter_height * filter_width)\n",
    "    Returns: \n",
    "        loss_contribution: The loss contribution from this layer \n",
    "    \"\"\"\n",
    "    \n",
    "    num_filters, _ = gram_matrix_desired.get_shape().as_list()\n",
    "    num_filters = float(num_filters)\n",
    "    summed_squared_difference = tf.reduce_sum(\n",
    "        tf.square(gram_matrix_predicted - gram_matrix_desired), name='summed_squared_diff')\n",
    "    loss_contribution = (1 / (4 * np.power(num_filters, 2) * np.power(filter_size, 2))) \\\n",
    "        * summed_squared_difference\n",
    "        \n",
    "    return loss_contribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up input node and feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The input node to the graph\n",
    "# These values are what is required by vgg19 for height, width, channels\n",
    "input_var_initial_value = np.random.rand(1, height, width, channels)\n",
    "input_var = tf.Variable(input_var_initial_value, dtype=tf.float32, name='input_var')\n",
    "\n",
    "# Load the vgg model\n",
    "with slim.arg_scope(vgg.vgg_arg_scope()):\n",
    "    end_points = vgg.vgg_19_conv(input_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up restoring feature extractor weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Prepare to restore the vgg19 nodes\n",
    "# Skip trying to restore the input variable since it's new\n",
    "all_variables = tf.get_collection_ref(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "saver = tf.train.Saver(var_list=all_variables[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load real image and create to-be optimised image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Construct the style image tensor\n",
    "# And the graph operation which assigns it to input_var\n",
    "real_image = plt.imread(real_image_path)\n",
    "real_image = cv2.resize(real_image, (height, width))\n",
    "real_image_batch = np.expand_dims(real_image, axis=0)\n",
    "real_image_batch = np.asarray(real_image_batch, dtype=np.float32)\n",
    "real_image_tensor = tf.Variable(real_image_batch, dtype=tf.float32, name='real_image')\n",
    "\n",
    "assign_real_image = tf.assign(input_var, real_image_tensor, name='assign_real_image')\n",
    "\n",
    "# Construct the white noise tensor\n",
    "# And the graph operation which assigns it to input_var\n",
    "white_noise = np.random.rand(height, width, channels) * 255.\n",
    "white_noise_batch = np.expand_dims(white_noise, axis=0)\n",
    "white_noise_batch = np.asarray(white_noise_batch, dtype=np.float32)\n",
    "white_noise_tensor = tf.Variable(white_noise_batch, dtype=tf.float32, name='white_noise')\n",
    "\n",
    "assign_white_noise = tf.assign(input_var, white_noise_tensor, name='assign_white_noise')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up gram matrix nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Choose which layers will be used to \n",
    "# reconstruct the original image\n",
    "grams = []\n",
    "filter_sizes = []\n",
    "for i in range(chosen_depth):\n",
    "    chosen_layer = end_points[feature_layer_list[i]]\n",
    "    gram_features = gram_matrix(chosen_layer)\n",
    "    grams.append(gram_features)\n",
    "    \n",
    "    # Determine the size of the filters used at each layer\n",
    "    # This is needed to calculate the loss from that layer\n",
    "    _, filter_height, filter_width, _ = chosen_layer.get_shape().as_list()\n",
    "    filter_size = float(filter_height * filter_width)\n",
    "    filter_sizes.append(filter_size)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain gram matrices for real image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer(),\n",
    "                  name='initialize_all')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Initialize new variables and then restore vgg_19 variables\n",
    "    sess.run(init_op)\n",
    "    saver.restore(sess, checkpoint_path)\n",
    "    \n",
    "    assign_real_image.eval()\n",
    "    \n",
    "    real_image_grams = sess.run(grams)\n",
    "    \n",
    "# Create constants with the real image gram matrices\n",
    "gram_constants = []\n",
    "for i in range(chosen_depth):\n",
    "    node_name = 'gram_constant_{}'.format(i)\n",
    "    gram_constant = tf.constant(real_image_grams[i], name=node_name)\n",
    "    gram_constants.append(gram_constant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the loss for each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layer_losses = []\n",
    "for i in range(chosen_depth):\n",
    "    layer_loss = style_layer_loss(gram_constants[i], grams[i], filter_sizes[i])\n",
    "    # Equal weighting on each loss, summing to 1\n",
    "    layer_loss *= (1.0 / chosen_depth)\n",
    "    layer_losses.append(layer_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the loss, optimizer, and summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set up final loss term and optimizer\n",
    "loss = tf.add_n(layer_losses, name='sum_layer_losses')\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "train_op = optimizer.minimize(loss, var_list=[input_var])\n",
    "\n",
    "# Initializers\n",
    "init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer(),\n",
    "                  name='initialize_all')\n",
    "\n",
    "# Tensorboard summaries\n",
    "loss_summary = tf.summary.scalar('loss', loss)\n",
    "image_summary = tf.summary.image('image', input_var)\n",
    "merged_summary = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess: \n",
    "    # Initialize all variables and then\n",
    "    # restore weights for feature extractor\n",
    "    sess.run(init_op)\n",
    "    saver.restore(sess, checkpoint_path)\n",
    "    \n",
    "    # Set up summary writer for tensorboard, saving graph as well\n",
    "    train_writer = tf.summary.FileWriter(tensorboard_dir, sess.graph)\n",
    "    \n",
    "    # Assign the white noise to the variable being optimized\n",
    "    assign_white_noise.eval()\n",
    "    \n",
    "    # Begin training\n",
    "    for i in range(training_steps):\n",
    "        loss_summary_, _ = sess.run([loss_summary, train_op])\n",
    "        train_writer.add_summary(loss_summary_, i)\n",
    "        \n",
    "        if i % validation_steps == 0:\n",
    "            image_summary_, current_image, loss_ = sess.run(\n",
    "                [image_summary, input_var, loss])\n",
    "            \n",
    "            train_writer.add_summary(image_summary_, i)\n",
    "            \n",
    "            print('Step: {}, Loss: {}'.format(i, loss_))\n",
    "            \n",
    "            if debug_online is True:\n",
    "                display_image(current_image, i)\n",
    "            if debug_offline is True:\n",
    "                save_image(current_image, i, debug_dir)  \n",
    "                \n",
    "    # Display and save the final image\n",
    "    current_image = input_var.eval()\n",
    "    display_image(current_image, 'Final')\n",
    "    save_image(current_image, 'Final', debug_dir)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
