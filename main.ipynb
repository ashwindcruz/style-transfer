{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "\n",
    "import vgg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input image dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "height = 224\n",
    "width = 224\n",
    "channels = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up input node and feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The input node to the graph\n",
    "input_var_initial_value = np.random.rand(1, height, width, channels)\n",
    "input_var = tf.Variable(input_var_initial_value, dtype=tf.float32, name='input_var')\n",
    "\n",
    "# Load the vgg model\n",
    "with slim.arg_scope(vgg.vgg_arg_scope()):\n",
    "    logits, end_points = vgg.vgg_19(input_var, num_classes=1000, is_training=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up restoring feature extractor weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Prepare to restore the vgg19 nodes\n",
    "# Skip trying to restore the input variable since it's new\n",
    "all_variables = tf.get_collection_ref(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "saver = tf.train.Saver(var_list=all_variables[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load real image and create to-be optimised image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Construct the real image tensor\n",
    "# And the graph operation which assigns it to input_var\n",
    "real_image = cv2.imread('./coastal_scene.jpg')\n",
    "real_image = cv2.resize(real_image, (height, width))\n",
    "real_image = cv2.cvtColor(real_image, cv2.COLOR_BGR2RGB)\n",
    "real_image_batch = np.expand_dims(real_image, axis=0)\n",
    "real_image_batch = np.asarray(real_image_batch, dtype=np.float32)\n",
    "real_image_tensor = tf.Variable(real_image_batch, dtype=tf.float32, name='real_image')\n",
    "\n",
    "assign_real_image = tf.assign(input_var, real_image_tensor, name='assign_real_image')\n",
    "\n",
    "# Construct the white noise tensor\n",
    "# And the graph operation which assigns it to input_var\n",
    "white_noise = np.random.rand(height, width, channels) * 255.\n",
    "white_noise_batch = np.expand_dims(white_noise, axis=0)\n",
    "white_noise_batch = np.asarray(white_noise_batch, dtype=np.float32)\n",
    "white_noise_tensor = tf.Variable(white_noise_batch, dtype=tf.float32, name='white_noise')\n",
    "\n",
    "assign_white_noise = tf.assign(input_var, white_noise_tensor, name='assign_white_noise')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up remaining graph nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Choose which representation will be used to\n",
    "# reconstruct the original image\n",
    "# TODO: This should be a parameter higher up in the code\n",
    "predictions = end_points['vgg_19/conv1/conv1_1']\n",
    "batch_size_res, height_res, width_res, channels_res = np.shape(predictions)\n",
    "\n",
    "# This placeholder will hold the response from the layer we are interested in\n",
    "# given the real image\n",
    "desired_response = tf.placeholder(tf.float32, \n",
    "                                  shape=[batch_size_res, height_res, width_res, channels_res],\n",
    "                                 name='desired_response')\n",
    "\n",
    "# Loss and optimizer\n",
    "loss = tf.losses.mean_squared_error(labels=desired_response, predictions=predictions)\n",
    "optimizer = tf.train.AdamOptimizer(1e-1)\n",
    "train_op = optimizer.minimize(loss, var_list=[input_var])\n",
    "\n",
    "# Tensorboard summaries\n",
    "loss_summary = tf.summary.scalar('loss', loss)\n",
    "image_summary = tf.summary.image('image', input_var)\n",
    "merged_summary = tf.summary.merge_all()\n",
    "\n",
    "# Initializers\n",
    "init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer(),\n",
    "                  name='initialize_all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function for displaying images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_to_proper(initial_image):\n",
    "    \"\"\"\n",
    "    Convert an image from tf node format to format that is \n",
    "    suitable for plt displaying.\n",
    "    \n",
    "    This involves ensuring the image is 3D (removing the batch dimension),\n",
    "    clipping the image to be between 0 and 255, rounding floats to int, and \n",
    "    setting the array type to be integers. \n",
    "    \n",
    "    Arguments:\n",
    "        initial_image: The original image from the node\n",
    "    Returns:\n",
    "        converted_image: Image to be shown by plt\n",
    "    \"\"\"\n",
    "    if np.ndim(initial_image) == 4:\n",
    "        initial_image = np.squeeze(initial_image, axis=0)\n",
    "    \n",
    "    image_clipped = np.clip(initial_image, 0, 255)\n",
    "    image_rounded = np.rint(image_clipped)\n",
    "    converted_image = np.asarray(image_rounded, dtype=np.uint8)\n",
    "    \n",
    "    return converted_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Initialize all variables and then\n",
    "    # restore weights for feature extractor\n",
    "    sess.run(init_op)\n",
    "    saver.restore(sess, './vgg_19.ckpt')\n",
    "    \n",
    "    # Set up summary writer for tensorboard\n",
    "    train_writer = tf.summary.FileWriter('./train', sess.graph)\n",
    "        \n",
    "    # Using the real image, get the response of the chosen layer\n",
    "    assign_real_image.eval()\n",
    "    desired_response_ = predictions.eval()\n",
    "    \n",
    "    # Assign the white noise to the image\n",
    "    assign_white_noise.eval()\n",
    "    \n",
    "    # Begin training\n",
    "    for i in range(5000):\n",
    "        input_var_, summary, loss_, _ = sess.run([input_var, merged_summary, loss, train_op], \n",
    "                                     feed_dict={desired_response:desired_response_})\n",
    "        train_writer.add_summary(summary, i)\n",
    "        \n",
    "        if i%100==0:\n",
    "            print('loss: {}'.format(loss_))\n",
    "            \n",
    "            input_var_ = input_var.eval()\n",
    "            input_var_ = np.squeeze(input_var_, axis=0)\n",
    "            plt.figure()\n",
    "            input_var_int = convert_to_proper(input_var_)\n",
    "            plt.imshow(input_var_int)\n",
    "            plt.title(str(i))\n",
    "            img_name = './debug/img_plt_{}.png'.format(str(i))\n",
    "            plt.savefig(img_name)\n",
    "            \n",
    "            input_var_colour = cv2.cvtColor(input_var_, cv2.COLOR_BGR2RGB)\n",
    "            img_name = './debug/img_{}.png'.format(str(i))\n",
    "            cv2.imwrite(img_name, input_var_colour)\n",
    "    \n",
    "    input_var_ = input_var.eval()\n",
    "    input_var_ = np.squeeze(input_var_, axis=0)\n",
    "    input_var_int = convert_to_proper(input_var_)\n",
    "    plt.figure()\n",
    "    plt.imshow(input_var_int)\n",
    "    plt.title('final')\n",
    "    plt.savefig('./debug/final_plt.png')\n",
    "    \n",
    "    input_var_colour = cv2.cvtColor(input_var_, cv2.COLOR_BGR2RGB)\n",
    "    cv2.imwrite('./debug/final.png', input_var_colour)   "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
