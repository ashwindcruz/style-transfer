{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "\n",
    "This notebook runs through Section 2.1:Content Reconstructions. \n",
    "The images generated are similar to those in Figure 1. \n",
    "\n",
    "The Directory Paths block should be edited to suit local directory structure. \n",
    "The Chosen Parameters block can be changed to try out different experimental settings. \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "\n",
    "import vgg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directory paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Path to image we are extracting content from\n",
    "real_image_path = './coastal_scene.jpg'\n",
    "\n",
    "# Path to vgg19 checkpoint, must be downloaded separately\n",
    "checkpoint_path = './vgg_19.ckpt'\n",
    "\n",
    "# Location of tensorboard summaries\n",
    "tensorboard_dir = './train/'\n",
    "\n",
    "# Path to directory used for storing images\n",
    "debug_dir = './debug/'\n",
    "\n",
    "# Determines whether information is saved between runs\n",
    "# for tensorboard\n",
    "reset_saves = True\n",
    "if reset_saves is True:\n",
    "    # Ensure tensorboard is not running when you try to delete\n",
    "    # this directory\n",
    "    if os.path.exists(tensorboard_dir):\n",
    "        shutil.rmtree(tensorboard_dir)\n",
    "        \n",
    "# Create the debug directory if it doesn't exist\n",
    "# Tensorboard directory is made automatically if it doesn't exist\n",
    "if os.path.exists(debug_dir):\n",
    "    shutil.rmtree(debug_dir)\n",
    "os.makedirs(debug_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chosen parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Layer being used to produce features\n",
    "feature_layer = 'vgg_19/conv2/conv2_2'\n",
    "\n",
    "# Learning rate for optimizer\n",
    "learning_rate = 1e-1\n",
    "\n",
    "# Number of training and validation step\n",
    "# In this instance, validation refers to when we would like to examine the \n",
    "# currently optimized image, save it, and loss\n",
    "training_steps = 100000\n",
    "validation_steps = 1000\n",
    "\n",
    "# Online debugging refers to images that will be displayed within the notebook \n",
    "# using plt\n",
    "# Offline debugging refers to images that will be saved to folder using plt\n",
    "debug_online = True\n",
    "debug_offline = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up input node and feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dimensions are required by vgg19\n",
    "height = 224\n",
    "width = 224\n",
    "channels = 3\n",
    "\n",
    "# Set the seeds to provide consistency between runs\n",
    "np.random.seed(0)\n",
    "tf.set_random_seed(0)\n",
    "\n",
    "# The input node to the graph\n",
    "# These values are what is required by vgg19 for height, width, channels\n",
    "input_var_initial_value = np.random.rand(1, height, width, channels)\n",
    "input_var = tf.Variable(input_var_initial_value, dtype=tf.float32, name='input_var')\n",
    "\n",
    "# Load the vgg model\n",
    "with slim.arg_scope(vgg.vgg_arg_scope()):\n",
    "    logits, end_points = vgg.vgg_19(input_var, num_classes=1000, is_training=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up restoring feature extractor weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Prepare to restore the vgg19 nodes\n",
    "# Skip trying to restore the input variable since it's new\n",
    "all_variables = tf.get_collection_ref(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "saver = tf.train.Saver(var_list=all_variables[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load real image and create to-be optimised image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Construct the real image tensor\n",
    "# And the graph operation which assigns it to input_var\n",
    "real_image = plt.imread(real_image_path)\n",
    "real_image = cv2.resize(real_image, (height, width))\n",
    "real_image_batch = np.expand_dims(real_image, axis=0)\n",
    "real_image_batch = np.asarray(real_image_batch, dtype=np.float32)\n",
    "real_image_tensor = tf.Variable(real_image_batch, dtype=tf.float32, name='real_image')\n",
    "\n",
    "assign_real_image = tf.assign(input_var, real_image_tensor, name='assign_real_image')\n",
    "\n",
    "# Construct the white noise tensor\n",
    "# And the graph operation which assigns it to input_var\n",
    "white_noise = np.random.rand(height, width, channels) * 255.\n",
    "white_noise_batch = np.expand_dims(white_noise, axis=0)\n",
    "white_noise_batch = np.asarray(white_noise_batch, dtype=np.float32)\n",
    "white_noise_tensor = tf.Variable(white_noise_batch, dtype=tf.float32, name='white_noise')\n",
    "\n",
    "assign_white_noise = tf.assign(input_var, white_noise_tensor, name='assign_white_noise')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up remaining graph nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Choose which representation will be used to\n",
    "# reconstruct the original image\n",
    "predictions = end_points[feature_layer]\n",
    "batch_size_res, height_res, width_res, channels_res = np.shape(predictions)\n",
    "\n",
    "# This placeholder will hold the response from the layer we are interested in\n",
    "# given the real image\n",
    "desired_response = tf.placeholder(tf.float32, \n",
    "                                  shape=[batch_size_res, height_res, width_res, channels_res],\n",
    "                                 name='desired_response')\n",
    "\n",
    "# Loss and optimizer\n",
    "loss = tf.losses.mean_squared_error(labels=desired_response, predictions=predictions)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "train_op = optimizer.minimize(loss, var_list=[input_var])\n",
    "\n",
    "# Tensorboard summaries\n",
    "loss_summary = tf.summary.scalar('loss', loss)\n",
    "image_summary = tf.summary.image('image', input_var)\n",
    "\n",
    "# Initializers\n",
    "init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer(),\n",
    "                  name='initialize_all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function for formatting images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def format_image(initial_image):\n",
    "    \"\"\"\n",
    "    Convert an image from tf node format to format that is \n",
    "    suitable for plt displaying.\n",
    "    \n",
    "    This involves ensuring the image is 3D (removing the batch dimension),\n",
    "    clipping the image to be between 0 and 255, rounding floats to int, and \n",
    "    setting the array type to be integers. \n",
    "    \n",
    "    Arguments:\n",
    "        initial_image: The original image from the node\n",
    "    Returns:\n",
    "        converted_image: Image to be shown by plt\n",
    "    \"\"\"\n",
    "    if np.ndim(initial_image) == 4:\n",
    "        initial_image = np.squeeze(initial_image, axis=0)\n",
    "    \n",
    "    image_clipped = np.clip(initial_image, 0, 255)\n",
    "    image_rounded = np.rint(image_clipped)\n",
    "    formatted_image = np.asarray(image_rounded, dtype=np.uint8)\n",
    "    \n",
    "    return formatted_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function for displaying images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_image(initial_image, fig_title):\n",
    "    \"\"\"\n",
    "    Display an image within the notebook.\n",
    "    \n",
    "    Arguments:\n",
    "        initial_image: The original image from the node\n",
    "        fig_title    : Title for this image \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    converted_image = format_image(initial_image)\n",
    "    plt.figure()\n",
    "    plt.imshow(converted_image)\n",
    "    plt.axis('off')\n",
    "    plt.title(fig_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function for saving images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_image(initial_image, fig_title):\n",
    "    \"\"\"\n",
    "    Save an image to disk.\n",
    "    \n",
    "    Arguments:\n",
    "        initial_image: The original image from the node\n",
    "        fig_title    : Title for this image \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    converted_image = format_image(initial_image)\n",
    "    img_name = './debug/img_{}.png'.format(fig_title)\n",
    "    plt.imsave(img_name, converted_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess: \n",
    "    # Initialize all variables and then\n",
    "    # restore weights for feature extractor\n",
    "    sess.run(init_op)\n",
    "    saver.restore(sess, checkpoint_path)\n",
    "    \n",
    "    # Set up summary writer for tensorboard\n",
    "    train_writer = tf.summary.FileWriter(tensorboard_dir, sess.graph)\n",
    "        \n",
    "    # Using the real image, get the response of the chosen layer\n",
    "    assign_real_image.eval()\n",
    "    desired_response_ = predictions.eval()\n",
    "    \n",
    "    # Assign the white noise to the image\n",
    "    assign_white_noise.eval()\n",
    "    \n",
    "    # Begin training\n",
    "    for i in range(training_steps):\n",
    "        summary, _ = sess.run([loss_summary, train_op], \n",
    "                                     feed_dict={desired_response:desired_response_})\n",
    "        train_writer.add_summary(summary, i)\n",
    "        \n",
    "        if i % validation_steps == 0:\n",
    "            summary, current_image, loss_ = sess.run([image_summary, input_var, loss],\n",
    "                                           feed_dict={desired_response:desired_response_})\n",
    "            train_writer.add_summary(summary, i)\n",
    "            \n",
    "            print('Step: {}, Loss: {}'.format(i, loss_))\n",
    "            \n",
    "            if debug_online is True:\n",
    "                display_image(current_image, i)\n",
    "            if debug_offline is True:\n",
    "                save_image(current_image, i)  \n",
    "                \n",
    "    # Display and save the final image\n",
    "    current_image = input_var.eval()\n",
    "    display_image(current_image, 'Final')\n",
    "    save_image(current_image, 'Final')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
